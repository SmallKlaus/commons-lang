name: SonarQube Historical Analysis (Decoupled)

on:
  workflow_dispatch:
    inputs:
      tagsToScan:
        description: 'Comma-separated Git tags to scan (e.g., v1.0.0,v1.1.0,v1.2.0)'
        required: true
        type: string

jobs:
  # Job 1: Checks out the repo once to prepare a list of tags and their dates
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix_json }}
    steps:
      - name: Checkout full repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history to read tags

      - name: Prepare matrix of tags and dates
        id: set-matrix
        run: |
          # This script creates a JSON array of objects, e.g., [{"tag":"v1.0","date":"2022-01-15"}, ...]
          tags_input="${{ github.event.inputs.tagsToScan }}"
          
          # This converts the comma-separated string to a newline-separated list and then version-sorts it.
          sorted_tags=$(echo "$tags_input" | sed 's/,/\n/g' | sort -V)

          json_objects=""
          for tag in $sorted_tags; do
            # Ensure the tag is not empty before processing
            if [ -n "$tag" ]; then
              date=$(git log -1 --format=%as "$tag")
              json_objects+=$(printf '{"tag":"%s","date":"%s"},' "$tag" "$date")
            fi
          done
          
          # Remove trailing comma and wrap in brackets to form a valid JSON array
          matrix_json=$(echo "[$json_objects]" | sed 's/,]$/]/')
          
          echo "matrix_json=$matrix_json" >> $GITHUB_OUTPUT

  # Job 2: Run all builds in parallel
  build-and-package:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        item: ${{ fromJSON(needs.setup.outputs.matrix) }}
      fail-fast: false

    name: Build Tag ${{ matrix.item.tag }}
    steps:
      - name: Checkout code at version ${{ matrix.item.tag }}
        uses: actions/checkout@v4
        with:
          ref: ${{ matrix.item.tag }}

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
      
      - name: Attempt initial build (with tests, parallel)
        id: initial-build
        continue-on-error: true
        run: |
          mvn clean verify

      - name: Retry build in safe mode (if initial build failed)
        if: steps.initial-build.outcome == 'failure'
        run: |
          echo "Initial build failed. Retrying in safe mode (skipping tests, single thread)..."
          mvn clean compile
      
      # --- START:  ARTIFACT UPLOAD LOGIC ---

      #  Sanitize the tag name using a shell command
      - name: Sanitize tag name for artifact
        id: sanitizer
        # This step only runs if a build was successful
        if: success()
        run: |
          # Bash parameter expansion to replace all instances of '/' with '-'
          tag_value="${{ matrix.item.tag }}"
          sanitized_name="${tag_value//\//-}"
          echo "sanitized_name=$sanitized_name" >> $GITHUB_OUTPUT

      - name: Upload build artifact
        # This step  only runs if a build was successful
        if: success()
        uses: actions/upload-artifact@v4
        with:
          # Use the output from the sanitizer step as the name
          name: build-results-${{ steps.sanitizer.outputs.sanitized_name }}
          path: .

    # Job 3: Submit, Wait, and Export Analysis for each version sequentially
  submit-and-export-sequentially:
    needs: [setup, build-and-package] # Runs only after all builds are done
    runs-on: ubuntu-latest
    name: Sequential Submit and Export

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      SONAR_ORG: smallklaus 
      SONAR_PROJECT: smallklaus_commons-lang  
      
    steps:
      # STEP 1: Checkout the full repository history to provide Git context
      - name: Checkout full repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # STEP 2: Download all the build artifacts from the parallel jobs
      - name: Download all build artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      # STEP 3: Create a directory to store the final reports
      - name: Create report directory
        run: mkdir -p reports
      
      # STEP 4: Loop through tags to submit, wait, and export
      - name: Submit, Wait, and Export Loop
        run: |
          previous_date=""
          for item in $(echo '${{ needs.setup.outputs.matrix }}' | jq -r '.[] | @base64'); do
            _jq() {
             echo ${item} | base64 --decode | jq -r ${1}
            }

            tag=$(_jq '.tag')
            date=$(_jq '.date')
            sanitized_tag=${tag//\//-}
            artifact_path="artifacts/build-results-$sanitized_tag"

            echo "--- Processing tag $tag ---"

            if [ ! -d "$artifact_path" ]; then
              echo "WARNING: Artifact for tag $tag not found, skipping."
              continue
            fi

            # PART A: PREPARE WORKING DIRECTORY
            echo "1. Checking out tag: $tag"
            git checkout -f "$tag"

            echo "2. Merging pre-built 'target' directory from artifact..."
            # Remove any existing target dir before copying to avoid conflicts
            rm -rf ./target
            cp -r "$artifact_path/target" .

            # PART B: SUBMIT ANALYSIS
            echo "3. Submitting SonarCloud analysis for $tag..."
            mvn -B sonar:sonar \
              -Dsonar.projectKey=${SONAR_PROJECT} \
              -Dsonar.organization=${SONAR_ORG} \
              -Dsonar.projectVersion=$tag \
              -Dsonar.host.url=https://sonarcloud.io \
              -Dsonar.projectDate=$date
            
            # PART C: WAIT FOR PROCESSING
            echo "4. Pausing for 60 seconds to allow SonarCloud to process the report..."
            sleep 60

            # PART D: EXPORT REPORTS
            echo "3. Exporting CSV reports for $tag..."
            
            # Metrics CSV
            metric_keys="bugs,reliability_rating,vulnerabilities,security_rating,security_hotspots,security_review_rating,code_smells,sqale_rating,sqale_index,sqale_debt_ratio,coverage,lines_to_cover,uncovered_lines,tests,test_success_density,duplicated_lines_density,duplicated_lines,duplicated_blocks,ncloc,lines,files,functions,classes,comment_lines_density,complexity,cognitive_complexity"
            metrics_response=$(curl -s -u "${SONAR_TOKEN}:" "https://sonarcloud.io/api/measures/component?component=${SONAR_PROJECT}&branch=${tag}&metricKeys=${metric_keys}")
            echo $(echo "$metrics_response" | jq -r '.component.measures | map(.metric) | @csv') > reports/metrics-${tag}.csv
            echo $(echo "$metrics_response" | jq -r '.component.measures | map(.value) | @csv') >> reports/metrics-${tag}.csv

            # Open Issues CSV
            echo "Key,Rule,Severity,Type,FilePath,Line,CreationDate,UpdateDate,TextRange,Message" > reports/open-issues-${tag}.csv
            page=1; while : ; do
              issues_response=$(curl -s -u "${SONAR_TOKEN}:" "https://sonarcloud.io/api/issues/search?componentKeys=${SONAR_PROJECT}&branch=${tag}&statuses=OPEN,CONFIRMED&ps=500&p=${page}&f=key,rule,severity,type,component,line,creationDate,updateDate,textRange,message")
              if [ -z "$(echo "$issues_response" | jq '.issues[]')" ]; then break; fi
              echo "$issues_response" | jq -r '.issues[] | [.key,.rule,.severity,.type,.component,.line,.message] | @csv' >> reports/open-issues-${tag}.csv
              page=$((page + 1)); done

            # Fixed Issues CSV
            if [ -n "$previous_date" ]; then
              echo "Key,Rule,Severity,Type,FilePath,Line,CreationDate,UpdateDate,TextRange,Message" > reports/fixed-issues-${tag}.csv
              page=1; while : ; do
                fixed_issues_response=$(curl -s -u "${SONAR_TOKEN}:" "https://sonarcloud.io/api/issues/search?componentKeys=${SONAR_PROJECT}&branch=${tag}&statuses=RESOLVED,CLOSED&resolutions=FIXED&resolvedAfter=${previous_date}&ps=500&p=${page}&f=key,rule,severity,type,component,line,creationDate,updateDate,textRange,message")
                if [ -z "$(echo "$fixed_issues_response" | jq '.issues[]')" ]; then break; fi
                echo "$fixed_issues_response" | jq -r '.issues[] | [.key,.rule,.severity,.type,.component,.line,.message] | @csv' >> reports/fixed-issues-${tag}.csv
                page=$((page + 1)); done
            fi
            
            previous_date=$date
            echo "--- Finished processing tag $tag ---"
            echo ""
          done

      # STEP 5: Upload all the generated reports as a single artifact
      - name: Upload All Reports
        uses: actions/upload-artifact@v4
        with:
          name: sonar-detailed-reports
          path: reports/
