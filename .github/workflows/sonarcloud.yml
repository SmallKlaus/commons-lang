name: SonarQube Historical Analysis (Decoupled)

on:
  workflow_dispatch:
    inputs:
      tagsToScan:
        description: 'Comma-separated Git tags to scan (e.g., v1.0.0,v1.1.0,v1.2.0)'
        required: true
        type: string

jobs:
  # Job 1: Checks out the repo once to prepare a list of tags and their dates
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix_json }}
    steps:
      - name: Checkout full repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history to read tags

      - name: Prepare matrix of tags and dates
        id: set-matrix
        run: |
          # This script creates a JSON array of objects, e.g., [{"tag":"v1.0","date":"2022-01-15"}, ...]
          tags_input="${{ github.event.inputs.tagsToScan }}"
          
          # This converts the comma-separated string to a newline-separated list and then version-sorts it.
          sorted_tags=$(echo "$tags_input" | sed 's/,/\n/g' | sort -V)

          json_objects=""
          for tag in $sorted_tags; do
            # Ensure the tag is not empty before processing
            if [ -n "$tag" ]; then
              date=$(git log -1 --format=%as "$tag")
              json_objects+=$(printf '{"tag":"%s","date":"%s"},' "$tag" "$date")
            fi
          done
          
          # Remove trailing comma and wrap in brackets to form a valid JSON array
          matrix_json=$(echo "[$json_objects]" | sed 's/,]$/]/')
          
          echo "matrix_json=$matrix_json" >> $GITHUB_OUTPUT

  # Job 2: Run all builds in parallel
  build-and-package:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        item: ${{ fromJSON(needs.setup.outputs.matrix) }}
      fail-fast: false

    name: Build Tag ${{ matrix.item.tag }}
    steps:
      - name: Checkout code at version ${{ matrix.item.tag }}
        uses: actions/checkout@v4
        with:
          ref: ${{ matrix.item.tag }}

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
      
      - name: Attempt initial build (with tests, parallel)
        id: initial-build
        continue-on-error: true
        run: |
          mvn clean verify

      - name: Retry build in safe mode (if initial build failed)
        if: steps.initial-build.outcome == 'failure'
        run: |
          echo "Initial build failed. Retrying in safe mode (skipping tests, single thread)..."
          mvn clean compile
      
      # --- START:  ARTIFACT UPLOAD LOGIC ---

      #  Sanitize the tag name using a shell command
      - name: Sanitize tag name for artifact
        id: sanitizer
        # This step only runs if a build was successful
        if: success()
        run: |
          # Bash parameter expansion to replace all instances of '/' with '-'
          tag_value="${{ matrix.item.tag }}"
          sanitized_name="${tag_value//\//-}"
          echo "sanitized_name=$sanitized_name" >> $GITHUB_OUTPUT

      - name: Upload build artifact
        # This step  only runs if a build was successful
        if: success()
        uses: actions/upload-artifact@v4
        with:
          # Use the output from the sanitizer step as the name
          name: build-results-${{ steps.sanitizer.outputs.sanitized_name }}
          path: .
  # Job 3: Submit all analyses sequentially
  submit-to-sonarcloud:
    needs: [setup, build-and-package] # Runs only after all builds are done
    runs-on: ubuntu-latest
    name: Sequential Sonar Submission

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      
    steps:
      - name: Checkout full repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts # Download all artifacts into a parent 'artifacts' directory

      - name: Submit analyses in order
        run: |
          for item in $(echo '${{ needs.setup.outputs.matrix }}' | jq -r '.[] | @base64'); do
            _jq() {
             echo ${item} | base64 --decode | jq -r ${1}
            }

            tag=$(_jq '.tag')
            date=$(_jq '.date')
            sanitized_tag=${tag//\//-}
            artifact_path="artifacts/build-results-$sanitized_tag"

            echo "--- Processing tag $tag ---"

            # Check if the corresponding artifact was actually downloaded
            if [ ! -d "$artifact_path" ]; then
              echo "WARNING: Artifact for tag $tag not found, skipping submission."
              continue
            fi

            # A) Switch the local Git repo to the correct tag
            echo "1. Checking out tag: $tag"
            git checkout -f "$tag"

            # B) Copy the pre-built 'target' directory from the artifact into our live Git checkout
            echo "2. Merging build results from artifact..."
            cp -r "$artifact_path/target" .
            
            # Run sonar:sonar from the downloaded project path
            mvn sonar:sonar \
              -Dsonar.projectKey=smallklaus_commons-lang \
              -Dsonar.organization=smallklaus \
              -Dsonar.projectVersion=$tag \
              -Dsonar.host.url=https://sonarcloud.io \
              -Dsonar.projectDate=$date
          done
  # Job 4: Export detailed analysis reports for each version to CSV files
  export-reports:
    needs: [setup, submit-to-sonarcloud] # Runs only after all submissions are done
    runs-on: ubuntu-latest
    name: Export Detailed CSV Reports

    steps:
      - name: Create report directory
        run: mkdir -p reports

      - name: Generate CSV reports for each version
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_ORG: smallklaus # Replace with your SonarCloud organization key
          SONAR_PROJECT: smallklaus_commons-lang # Replace with your SonarCloud project key
        run: |
          previous_date=""
          # Use jq to iterate through the JSON array from the setup job, ensuring order
          for item in $(echo '${{ needs.setup.outputs.matrix }}' | jq -r '.[] | @base64'); do
            _jq() {
             echo ${item} | base64 --decode | jq -r ${1}
            }

            tag=$(_jq '.tag')
            date=$(_jq '.date')
            
            echo "--- Generating reports for tag: $tag ---"

            # --- 1. METRICS CSV ---
            echo "Generating metrics CSV..."
            metric_keys="bugs,reliability_rating,vulnerabilities,security_rating,security_hotspots,security_review_rating,code_smells,sqale_rating,sqale_index,sqale_debt_ratio,coverage,lines_to_cover,uncovered_lines,tests,test_success_density,duplicated_lines_density,duplicated_lines,duplicated_blocks,ncloc,lines,files,functions,classes,comment_lines_density,complexity,cognitive_complexity"
            
            metrics_response=$(curl -s -u "${SONAR_TOKEN}:" \
              "https://sonarcloud.io/api/measures/component?component=${SONAR_PROJECT}&branch=${tag}&metricKeys=${metric_keys}")

            echo $(echo "$metrics_response" | jq -r '.component.measures | map(.metric) | @csv') > reports/metrics-${tag}.csv
            echo $(echo "$metrics_response" | jq -r '.component.measures | map(.value) | @csv') >> reports/metrics-${tag}.csv


            # --- 2. OPEN ISSUES CSV ---
            echo "Generating open issues CSV..."
            echo "Key,Rule,Severity,Type,FilePath,Line,CreationDate,UpdateDate,TextRange,Message" > reports/open-issues-${tag}.csv
            page=1
            while : ; do
              issues_response=$(curl -s -u "${SONAR_TOKEN}:" \
                "https://sonarcloud.io/api/issues/search?componentKeys=${SONAR_PROJECT}&branch=${tag}&statuses=OPEN,CONFIRMED&ps=500&p=${page}&f=key,rule,severity,type,component,line,creationDate,updateDate,textRange,message")
              
              if [ -z "$(echo "$issues_response" | jq '.issues[]')" ]; then break; fi

              echo "$issues_response" | jq -r '.issues[] | [.key,.rule,.severity,.type,.component,.line,.creationDate,.updateDate,(.textRange|tostring),.message] | @csv' >> reports/open-issues-${tag}.csv
              
              page=$((page + 1))
            done


            # --- 3. FIXED ISSUES CSV ---
            if [ -n "$previous_date" ]; then
              echo "Generating fixed issues CSV (since $previous_date)..."
              echo "Key,Rule,Severity,Type,FilePath,Line,CreationDate,UpdateDate,TextRange,Message" > reports/fixed-issues-${tag}.csv
              page=1
              while : ; do
                fixed_issues_response=$(curl -s -u "${SONAR_TOKEN}:" \
                  "https://sonarcloud.io/api/issues/search?componentKeys=${SONAR_PROJECT}&branch=${tag}&statuses=RESOLVED,CLOSED&resolutions=FIXED&resolvedAfter=${previous_date}&ps=500&p=${page}&f=key,rule,severity,type,component,line,creationDate,updateDate,textRange,message")
                
                if [ -z "$(echo "$fixed_issues_response" | jq '.issues[]')" ]; then break; fi

                echo "$fixed_issues_response" | jq -r '.issues[] | [.key,.rule,.severity,.type,.component,.line,.creationDate,.updateDate,(.textRange|tostring),.message] | @csv' >> reports/fixed-issues-${tag}.csv
                
                page=$((page + 1))
              done
            fi
            
            previous_date=$date
            echo "--- Finished reports for $tag ---"
          done

      - name: Upload All Reports
        uses: actions/upload-artifact@v4
        with:
          name: sonar-detailed-reports
          path: reports/
